{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000001D7E9D6CDD0>\n",
      "base2\n",
      "base3\n",
      "dataspark\n",
      "demopro\n",
      "guvi\n",
      "information_schema\n",
      "mysql\n",
      "performance_schema\n",
      "phpmyadmin\n",
      "redbuss\n",
      "schooldb\n",
      "sportradar\n",
      "tennis_data\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mydb=mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "Mycursor=mydb.cursor(buffered=True)  # cursor is intracting point between mysql and python\n",
    "\n",
    "# create database\n",
    "Mycursor.execute('create database SportRadar')\n",
    "print('the databases created')\n",
    "\n",
    "# Show database\n",
    "Mycursor.execute('show databases')\n",
    "for i in Mycursor:\n",
    "    print(''.join(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the database has been dropped\n"
     ]
    }
   ],
   "source": [
    "Mycursor.execute('drop database SportRadar')\n",
    "print('the database has been dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store datasets in 'sportrader' database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Categories Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   category_id    5796 non-null   object\n",
      " 1   category_name  5796 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 90.7+ KB\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Categories Table.csv')\n",
    "Categories_table=df.copy()\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "#information about the dataset\n",
    "Categories_table.info()\n",
    "# drop duplicates\n",
    "Categories_table.drop_duplicates(subset=['category_id'],inplace=True)\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Categories_table(category_id varchar(50),category_name varchar(100) not null,PRIMARY KEY (category_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Categories_Table(category_id,category_name) values(%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Categories_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['category_id'],row['category_name']))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "mydb.commit()\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Categories_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Competitions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   competition_id    5796 non-null   object\n",
      " 1   competition_name  5796 non-null   object\n",
      " 2   parent_id         5756 non-null   object\n",
      " 3   type              5796 non-null   object\n",
      " 4   gender            5796 non-null   object\n",
      " 5   category_id       5796 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 271.8+ KB\n",
      "The data has been uploaded. Total rows in table: 5796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Competitions Table.csv')\n",
    "Competitions_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Competitions_table.info()\n",
    "# drop Duplicates by 'competition_id'\n",
    "Competitions_table.drop_duplicates(subset=['competition_id'],inplace=True)\n",
    "\n",
    "# Convert missing values to None (for MySQL compatibility)\n",
    "Competitions_table['parent_id'] = Competitions_table['parent_id'].apply(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Competitions_table(competition_id varchar(50) ,competition_name varchar(100) not null,parent_id varchar(50) null,type varchar(20) not null,gender varchar(10) not null,category_id varchar(50),primary key(competition_id),FOREIGN KEY (category_id) REFERENCES SportRadar.Categories_table(category_id))')\n",
    "#print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Competitions_table(competition_id,competition_name,parent_id,type,gender,category_id)values(%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Competitions_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['competition_id'],row['competition_name'],row['parent_id'],row['type'],row['gender'],row['category_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "        \n",
    "mydb.commit()\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Competitions_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Complexes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 609 entries, 0 to 608\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   complex_id    609 non-null    object\n",
      " 1   complex_name  609 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.6+ KB\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Complexes Table.csv')\n",
    "Complexes_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Complexes_table.info()\n",
    "# drop duplicates\n",
    "Complexes_table.drop_duplicates(subset=['complex_id'],inplace=True)\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Complexes_table(complex_id varchar(50),complex_name varchar(100) not null,primary key(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Complexes_table(complex_id,complex_name)values(%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Complexes_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['complex_id'],row['complex_name']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "#commit changes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Complexes_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Venues Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3144 entries, 0 to 3143\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   venue_id      3144 non-null   object\n",
      " 1   venue_name    3144 non-null   object\n",
      " 2   city_name     3144 non-null   object\n",
      " 3   country_name  3144 non-null   object\n",
      " 4   country_code  3144 non-null   object\n",
      " 5   timezone      3144 non-null   object\n",
      " 6   complex_id    3144 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 172.1+ KB\n",
      "venue_id        0\n",
      "venue_name      0\n",
      "city_name       0\n",
      "country_name    0\n",
      "country_code    0\n",
      "timezone        0\n",
      "complex_id      0\n",
      "dtype: int64\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 3144\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Venues Table.csv')\n",
    "Venues_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "#informtion about the dataset\n",
    "Venues_table.info()\n",
    "#check null values by related columns\n",
    "missing=Venues_table.loc[Venues_table['timezone'].isna(),['country_name','city_name','timezone']]\n",
    "missing.drop_duplicates()\n",
    "# mapping the missing timezone\n",
    "fill_missing = {('France', 'Orchies'): 'Europe/Paris',('Singapore', 'Kallang'): 'Asia/Singapore',('China', 'Zhuhai'): 'Asia/Shanghai',('Russia', 'Moscow'): 'Europe/Moscow',('Chile', 'Vina del Mar'): 'America/Santiago',('China', 'Liuzhou'): 'Asia/Shanghai',('Uruguay', 'Punta del Este'): 'America/Montevideo',('Austria', 'Tulln'): 'Europe/Vienna',('Monaco', 'Monte Carlo'): 'Europe/Paris',('Germany', 'Baden-Wurttemberg'): 'Europe/Berlin',('Switzerland', 'Montreux'): 'Europe/Zurich',('China', 'Jiujiang'): 'Asia/Shanghai',('France', 'Decines-Charpieu'): 'Europe/Paris',('Thailand','Nonthaburi'):'Asia/Bangkok'}\n",
    "# fill missing values by 'combine key' column\n",
    "Venues_table['combined_key'] = list(zip(Venues_table['country_name'], Venues_table['city_name']))\n",
    "Venues_table['timezone'] = Venues_table['combined_key'].map(fill_missing).fillna(Venues_table['timezone'])\n",
    "#drop the column\n",
    "Venues_table.drop(columns=['combined_key'], inplace=True)\n",
    "# check null values are there  \n",
    "print(Venues_table.isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Venues_table(venue_id varchar(50),venue_name varchar(100) not null,city_name varchar(100) not null,country_name varchar(100) not null,country_code char(3) not null,timezone varchar(100) not null,complex_id varchar(50),primary key(venue_id),foreign key (complex_id) references SportRadar.Complexes_table(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Venues_table(venue_id,venue_name,city_name,country_name,country_code,timezone,complex_id)values(%s,%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Venues_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['venue_id'],row['venue_name'],row['city_name'],row['country_name'],row['country_code'],row['timezone'],row['complex_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "#commit changes\n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Venues_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Competitor_Rankings Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   rank_id              1000 non-null   int64 \n",
      " 1   rank                 1000 non-null   int64 \n",
      " 2   movement             1000 non-null   int64 \n",
      " 3   points               1000 non-null   int64 \n",
      " 4   competitions_played  1000 non-null   int64 \n",
      " 5   competitor_id        1000 non-null   object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 47.0+ KB\n",
      "rank_id                0\n",
      "rank                   0\n",
      "movement               0\n",
      "points                 0\n",
      "competitions_played    0\n",
      "competitor_id          0\n",
      "dtype: int64\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Competitor_Rankings Table.csv')\n",
    "Competitor_Rankings_table=df.copy()\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Competitor_Rankings_table.info()\n",
    "# drop duplicates\n",
    "Competitor_Rankings_table.drop_duplicates(subset=['rank_id'],inplace=True)\n",
    "# check null values\n",
    "print(Competitor_Rankings_table.isna().sum())\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Competitor_Rankings_table(rank_id int AUTO_INCREMENT ,rank int not null,movement int not null,points int not null,competitions_played int not null,competitor_id varchar(50),primary key (rank_id),FOREIGN KEY (competitor_id) REFERENCES SportRadar.competitors_table(competitor_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Competitor_Rankings_table(rank,movement,points,competitions_played,competitor_id)values(%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Competitor_Rankings_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['rank'],row['movement'],row['points'],row['competitions_played'],row['competitor_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# committ changes\n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Competitor_Rankings_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Competitors Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   competitor_id  1000 non-null   object\n",
      " 1   name           1000 non-null   object\n",
      " 2   country        1000 non-null   object\n",
      " 3   country_code   931 non-null    object\n",
      " 4   abbreviation   1000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.2+ KB\n",
      "competitor_id    0\n",
      "name             0\n",
      "country          0\n",
      "country_code     0\n",
      "abbreviation     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCOT\\AppData\\Local\\Temp\\ipykernel_7308\\3290598055.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  competitors_table['country_code'].fillna('NTL',inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import file to store\n",
    "df=pd.read_csv(r'D:\\workpads\\MDTE15\\project-1\\Competitors Table.csv')\n",
    "competitors_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataet\n",
    "competitors_table.info()\n",
    "# Drop duplicate rows based on 'competitor_id'\n",
    "competitors_table.drop_duplicates(subset=['competitor_id'],inplace=True)\n",
    "# check null values\n",
    "competitors_table.loc[competitors_table['country_code'].isna(),'country']\n",
    "competitors_table[competitors_table['country']=='Neutral']\n",
    "competitors_table['country_code'].fillna('NTL',inplace=True)\n",
    "# ensure the null values\n",
    "print(competitors_table.isna().sum())\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.competitors_table(competitor_id varchar(50),name varchar(100) not null,country varchar(100) not null,country_code char(3) not null,abbreviation varchar(10) not null,primary key (competitor_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.competitors_table(competitor_id,name,country,country_code,abbreviation)values(%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in competitors_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['competitor_id'],row['name'],row['country'],row['country_code'],row['abbreviation']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# committ chanes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.competitors_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
